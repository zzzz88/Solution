# -*- coding: utf-8 -*-
"""
Created on Sun Apr  5 20:39:48 2020

@author: Daizh
"""

import pandas as pd
holdout = pd.read_csv("test.csv")
train = pd.read_csv("train.csv")
def process_age(df):
    df["Age"] = df["Age"].fillna(-0.5)
    cut_points = [-1,0,5,12,18,35,60,100]
    label_names = ["Missing","Infant","Child","Teenager","Young Adult","Adult","Senior"]
    df["Age_categories"] = pd.cut(df["Age"],cut_points,labels=label_names)
    return df

def create_dummies(df,column_name):
    dummies = pd.get_dummies(df[column_name],prefix=column_name)
    df = pd.concat([df,dummies],axis=1)
    return df
train = process_age(train)
holdout = process_age(holdout)
dummies_columns = ['Age_categories','Pclass','Sex']
for col in dummies_columns:
    train = create_dummies(train,col)
    holdout = create_dummies(holdout,col)
print(train.columns)
from sklearn.preprocessing import minmax_scale
holdout["Fare"] = holdout["Fare"].fillna(train["Fare"].mean())
train['Embarked'] = train['Embarked'].fillna('S')
holdout['Embarked'] = holdout['Embarked'].fillna('S')
train = create_dummies(train,'Embarked')
holdout = create_dummies(holdout,'Embarked')
preprocess_columns = ['SibSp','Parch','Fare']
for col in preprocess_columns:
    
    train[col +"_scaled" ] = minmax_scale(train[col])
    holdout[col +"_scaled"] = minmax_scale(holdout[col])
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression

columns = ['Age_categories_Missing', 'Age_categories_Infant',
       'Age_categories_Child', 'Age_categories_Teenager',
       'Age_categories_Young Adult', 'Age_categories_Adult',
       'Age_categories_Senior', 'Pclass_1', 'Pclass_2', 'Pclass_3',
       'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S',
       'SibSp_scaled', 'Parch_scaled', 'Fare_scaled']
lr = LogisticRegression()
lr.fit(train[columns],train.Survived)
coefficients =lr.coef_
feature_importance = pd.Series(coefficients[0],index = columns)
feature_importance.plot.barh()
plt.show()
ordered_feature_importance = feature_importance.abs().sort_values()
ordered_feature_importance.plot.barh()
plt.show()
## select top 8 scores for training##
from sklearn.model_selection import cross_val_score
columns = ['Age_categories_Infant', 'SibSp_scaled', 'Sex_female', 'Sex_male',
       'Pclass_1', 'Pclass_3', 'Age_categories_Senior', 'Parch_scaled']
lr = LogisticRegression()
scores =cross_val_score(lr, train[columns],train.Survived, cv =10)
accuracy = scores.mean()
all_X = train[columns]
all_y = train['Survived']
lr.fit(all_X,all_y)
holdout_predictions = lr.predict(holdout[columns])
holdout_ids = holdout.PassengerId
submission_df = {
            'PassengerId': holdout_ids,
            'Survived': holdout_predictions
}
submission =pd.DataFrame(submission_df)
submission.to_csv('submission_1.csv',index =False)
##above method imporve accuracy from 80% to 81.4%##
## Feacture Engineering (binning)##
def process_age(df,cut_points,label_names):
    df["Age"] = df["Age"].fillna(-0.5)
    df["Age_categories"] = pd.cut(df["Age"],cut_points,labels=label_names)
    return df
def process_fare(df, cut_points, label_names):
    df['Fare_categories'] = pd.cut(df['Fare'],cut_points,labels = label_names)
    return df
fare_label = ['0-12','12-50','50-100','100+']
cut_points_fare =[0,12,50,100,1000]
train = process_fare(train,cut_points_fare,fare_label)
holdout = process_fare(holdout,cut_points_fare,fare_label)
train = create_dummies(train,'Fare_categories')
holdout =create_dummies(holdout,'Fare_categories')
titles = {
    "Mr" :         "Mr",
    "Mme":         "Mrs",
    "Ms":          "Mrs",
    "Mrs" :        "Mrs",
    "Master" :     "Master",
    "Mlle":        "Miss",
    "Miss" :       "Miss",
    "Capt":        "Officer",
    "Col":         "Officer",
    "Major":       "Officer",
    "Dr":          "Officer",
    "Rev":         "Officer",
    "Jonkheer":    "Royalty",
    "Don":         "Royalty",
    "Sir" :        "Royalty",
    "Countess":    "Royalty",
    "Dona":        "Royalty",
    "Lady" :       "Royalty"
}

extracted_titles = train["Name"].str.extract(' ([A-Za-z]+)\.',expand=False)
train['Title'] = extracted_titles.map(titles)
holdout['Title'] = holdout['Name'].str.extract(' ([A-Za-z]+)\.',expand=False).map(titles)
train['Cabin_type'] = train['Cabin'].str[0]
train['Cabin_type'] = train.Cabin_type.fillna('Unknown')
holdout['Cabin_type'] = holdout['Cabin'].str[0]
holdout['Cabin_type'] = holdout.Cabin_type.fillna('Unknown')
train = create_dummies(train,'Title')
train = create_dummies(train,'Cabin_type')
holdout = create_dummies(holdout,'Title')
holdout = create_dummies(holdout,'Cabin_type')
import numpy as np
import seaborn as sns
def plot_correlation_heatmap(df):
    corr = df.corr()
    
    sns.set(style="white")
    mask = np.zeros_like(corr, dtype=np.bool)
    mask[np.triu_indices_from(mask)] = True

    f, ax = plt.subplots(figsize=(11, 9))
    cmap = sns.diverging_palette(220, 10, as_cmap=True)


    sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,
            square=True, linewidths=.5, cbar_kws={"shrink": .5})
    plt.show()

columns = ['Age_categories_Missing', 'Age_categories_Infant',
       'Age_categories_Child', 'Age_categories_Teenager',
       'Age_categories_Young Adult', 'Age_categories_Adult',
       'Age_categories_Senior', 'Pclass_1', 'Pclass_2', 'Pclass_3',
       'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S',
       'SibSp_scaled', 'Parch_scaled', 'Fare_categories_0-12',
       'Fare_categories_12-50','Fare_categories_50-100', 'Fare_categories_100+',
       'Title_Master', 'Title_Miss', 'Title_Mr','Title_Mrs', 'Title_Officer',
       'Title_Royalty', 'Cabin_type_A','Cabin_type_B', 'Cabin_type_C', 'Cabin_type_D',
       'Cabin_type_E','Cabin_type_F', 'Cabin_type_G', 'Cabin_type_T', 'Cabin_type_Unknown']
plot_correlation_heatmap(train[columns])

from sklearn.feature_selection import RFECV

columns = ['Age_categories_Missing', 'Age_categories_Infant',
       'Age_categories_Child', 'Age_categories_Young Adult',
       'Age_categories_Adult', 'Age_categories_Senior', 'Pclass_1', 'Pclass_3',
       'Embarked_C', 'Embarked_Q', 'Embarked_S', 'SibSp_scaled',
       'Parch_scaled', 'Fare_categories_0-12', 'Fare_categories_50-100',
       'Fare_categories_100+', 'Title_Miss', 'Title_Mr', 'Title_Mrs',
       'Title_Officer', 'Title_Royalty', 'Cabin_type_B', 'Cabin_type_C',
       'Cabin_type_D', 'Cabin_type_E', 'Cabin_type_F', 'Cabin_type_G',
       'Cabin_type_T', 'Cabin_type_Unknown']


all_X = train[columns]
all_y = train["Survived"]
lr = LogisticRegression()
selector = RFECV(lr,cv=10)
selector.fit(all_X,all_y)
optimized_columns = all_X.columns[selector.support_]
all_X = train[optimized_columns]
all_y = train["Survived"]
from sklearn.model_selection import cross_val_score
scores = cross_val_score(selector, all_X,all_y, cv =10)
accuracy = scores.mean()
##accuracy improved to 82.3%  ##
lr = LogisticRegression()
lr.fit(all_X,all_y)
holdout_predictions = lr.predict(holdout[optimized_columns])
submission_df = {
            'PassengerId': holdout['PassengerId'],
            'Survived': holdout_predictions
}
submission = pd.DataFrame(submission_df)
submission.to_csv('submission_2.csv', index = False)
